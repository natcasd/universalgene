{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n"
     ]
    }
   ],
   "source": [
    "# Create necessary directories\n",
    "os.makedirs('./models/dann/', exist_ok=True)\n",
    "\n",
    "# 1. Data Loading and Preparation\n",
    "print(\"Loading and preparing data...\")\n",
    "with open('./src/data/tabula_muris/preprocessed/tm_adata_all.pkl', 'rb') as f:\n",
    "    adata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract gene expression data and domain labels\n",
    "X = adata.X  # Gene expression matrix\n",
    "\n",
    "# Convert sparse matrix to dense\n",
    "if sp.issparse(X):\n",
    "    X = X.toarray()\n",
    "\n",
    "# Extract domain labels\n",
    "domain_labels = adata.obs['tech'].astype('category').cat.codes\n",
    "domain_tensor = torch.tensor(domain_labels.values, dtype=torch.long)\n",
    "\n",
    "# Extract cell type labels\n",
    "adata.obs['cell_ontology_class'] = adata.obs['cell_ontology_class'].astype('category')\n",
    "cell_labels = adata.obs['cell_ontology_class'].cat.codes\n",
    "cell_tensor = torch.tensor(cell_labels.values, dtype=torch.long)\n",
    "\n",
    "# Save for decoding later (optional)\n",
    "cell_label_decoder = dict(enumerate(adata.obs['cell_ontology_class'].cat.categories))\n",
    "\n",
    "# Standardize gene expression data\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "\n",
    "# Total number of cells\n",
    "num_cell_classes = len(torch.unique(cell_tensor))\n",
    "\n",
    "# ðŸ“Œ Now split X, domain labels, and cell labels together\n",
    "X_train, X_val, domain_train, domain_val, cell_train, cell_val = train_test_split(\n",
    "    X_tensor, domain_tensor, cell_tensor,\n",
    "    test_size=0.2, random_state=42, stratify=domain_tensor  # or stratify=cell_tensor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientReversalLayer(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.alpha, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.relu(self.fc2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DomainClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)  # Binary classification: Sampling Technique 1 vs 2\n",
    "\n",
    "    def forward(self, x, alpha=1.0):\n",
    "        x = GradientReversalLayer.apply(x, alpha)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.log_softmax(self.fc2(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(CellClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.log_softmax(self.fc2(x), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SingleCellDataset(Dataset):\n",
    "    def __init__(self, X, domain_labels, cell_labels):\n",
    "        self.X = X\n",
    "        self.domain_labels = domain_labels\n",
    "        self.cell_labels = cell_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.domain_labels[idx], self.cell_labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = X_tensor.shape[1]\n",
    "hidden_dim = 512\n",
    "lambda_domain = 1.0\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Initialize models\n",
    "encoder = Encoder(input_dim, hidden_dim)\n",
    "domain_classifier = DomainClassifier(128)\n",
    "cell_classifier = CellClassifier(128, num_cell_classes)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(encoder.parameters()) +\n",
    "    list(domain_classifier.parameters()) +\n",
    "    list(cell_classifier.parameters()),\n",
    "    lr=learning_rate\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oscar/data/rsingh47/wli115/scGrapHiCv2/pytorch.venv/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create datasets and dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataset = SingleCellDataset(X_train, domain_train, cell_train)\n",
    "val_dataset = SingleCellDataset(X_val, domain_val, cell_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Encoder parameters: <generator object Module.parameters at 0x7fb4787a39e0>\n",
      "Domain classifier parameters: <generator object Module.parameters at 0x7fb4787a3900>\n",
      "Cell classifier parameters: <generator object Module.parameters at 0x7fb4787a39e0>\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder.to(device)\n",
    "domain_classifier.to(device)\n",
    "cell_classifier.to(device)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Encoder parameters: {encoder.parameters()}\")\n",
    "print(f\"Domain classifier parameters: {domain_classifier.parameters()}\")\n",
    "print(f\"Cell classifier parameters: {cell_classifier.parameters()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def train_epoch(encoder, domain_classifier, cell_classifier, train_loader, optimizer, lambda_domain, epoch, num_epochs):\n",
    "    encoder.train()\n",
    "    domain_classifier.train()\n",
    "    cell_classifier.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_cell_acc = 0\n",
    "    total_domain_acc = 0\n",
    "\n",
    "    for batch_X, batch_domain, batch_cell in train_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_domain = batch_domain.to(device)\n",
    "        batch_cell = batch_cell.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        alpha = 2. / (1. + np.exp(-10 * epoch / num_epochs)) - 1\n",
    "        encoded = encoder(batch_X)\n",
    "        \n",
    "        domain_preds = domain_classifier(encoded, alpha=alpha)\n",
    "        cell_preds = cell_classifier(encoded)\n",
    "        \n",
    "        # Losses\n",
    "        domain_loss = F.nll_loss(domain_preds, batch_domain)\n",
    "        cell_loss = F.nll_loss(cell_preds, batch_cell)\n",
    "        loss = cell_loss + lambda_domain * domain_loss\n",
    "        \n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Metrics\n",
    "        total_loss += loss.item()\n",
    "        total_cell_acc += (cell_preds.argmax(1) == batch_cell).float().mean().item()\n",
    "        total_domain_acc += (domain_preds.argmax(1) == batch_domain).float().mean().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_cell_acc = total_cell_acc / len(train_loader)\n",
    "    avg_domain_acc = total_domain_acc / len(train_loader)\n",
    "\n",
    "    return avg_loss, avg_cell_acc, avg_domain_acc\n",
    "\n",
    "def validate(encoder, domain_classifier, cell_classifier, val_loader, lambda_domain):\n",
    "    encoder.eval()\n",
    "    domain_classifier.eval()\n",
    "    cell_classifier.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_cell_acc = 0\n",
    "    total_domain_acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_domain, batch_cell in val_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_domain = batch_domain.to(device)\n",
    "            batch_cell = batch_cell.to(device)\n",
    "            \n",
    "            encoded = encoder(batch_X)\n",
    "            domain_preds = domain_classifier(encoded, alpha=1.0)  # Full strength at validation\n",
    "            cell_preds = cell_classifier(encoded)\n",
    "\n",
    "            domain_loss = F.nll_loss(domain_preds, batch_domain)\n",
    "            cell_loss = F.nll_loss(cell_preds, batch_cell)\n",
    "            loss = cell_loss + lambda_domain * domain_loss\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_cell_acc += (cell_preds.argmax(1) == batch_cell).float().mean().item()\n",
    "            total_domain_acc += (domain_preds.argmax(1) == batch_domain).float().mean().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    avg_cell_acc = total_cell_acc / len(val_loader)\n",
    "    avg_domain_acc = total_domain_acc / len(val_loader)\n",
    "\n",
    "    return avg_loss, avg_cell_acc, avg_domain_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/100\n",
      "  Train Loss: 1.0429, Cell Acc: 0.7991, Domain Acc: 0.8871\n",
      "  Val   Loss: 0.6388, Cell Acc: 0.8540, Domain Acc: 0.9415\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m val_accuracies \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 9\u001b[0m     train_loss, train_cell_acc, train_domain_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_classifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_domain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     val_loss, val_cell_acc, val_domain_acc \u001b[38;5;241m=\u001b[39m validate(\n\u001b[1;32m     15\u001b[0m         encoder, domain_classifier, cell_classifier,\n\u001b[1;32m     16\u001b[0m         val_loader, lambda_domain\n\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     19\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[14], line 22\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(encoder, domain_classifier, cell_classifier, train_loader, optimizer, lambda_domain, epoch, num_epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m encoded \u001b[38;5;241m=\u001b[39m encoder(batch_X)\n\u001b[1;32m     21\u001b[0m domain_preds \u001b[38;5;241m=\u001b[39m domain_classifier(encoded, alpha\u001b[38;5;241m=\u001b[39malpha)\n\u001b[0;32m---> 22\u001b[0m cell_preds \u001b[38;5;241m=\u001b[39m \u001b[43mcell_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Losses\u001b[39;00m\n\u001b[1;32m     25\u001b[0m domain_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(domain_preds, batch_domain)\n",
      "File \u001b[0;32m/oscar/data/rsingh47/wli115/scGrapHiCv2/pytorch.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/oscar/data/rsingh47/wli115/scGrapHiCv2/pytorch.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m, in \u001b[0;36mCellClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m----> 8\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m(x))\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlog_softmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/oscar/data/rsingh47/wli115/scGrapHiCv2/pytorch.venv/lib64/python3.9/site-packages/torch/nn/modules/module.py:1924\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1922\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _parameters[name]\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_buffers\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m-> 1924\u001b[0m     _buffers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_buffers\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _buffers:\n\u001b[1;32m   1926\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _buffers[name]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_cell_acc, train_domain_acc = train_epoch(\n",
    "        encoder, domain_classifier, cell_classifier,\n",
    "        train_loader, optimizer, lambda_domain, epoch, num_epochs\n",
    "    )\n",
    "\n",
    "    val_loss, val_cell_acc, val_domain_acc = validate(\n",
    "        encoder, domain_classifier, cell_classifier,\n",
    "        val_loader, lambda_domain\n",
    "    )\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    train_accuracies.append(train_cell_acc)\n",
    "    val_accuracies.append(val_cell_acc)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Cell Acc: {train_cell_acc:.4f}, Domain Acc: {train_domain_acc:.4f}\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f}, Cell Acc: {val_cell_acc:.4f}, Domain Acc: {val_domain_acc:.4f}\")\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Visualization and Analysis\n",
    "print(\"Generating visualizations...\")\n",
    "\n",
    "os.makedirs('./src/models/dann/', exist_ok=True)\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.savefig('./src/models/dann/training_curves.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot training and validation accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracies')\n",
    "plt.legend()\n",
    "plt.savefig('./src/models/dann/accuracies.png')\n",
    "plt.close()\n",
    "\n",
    "# Move model to GPU\n",
    "encoder = encoder.to(device)\n",
    "X_tensor = X_tensor.to(device)\n",
    "\n",
    "# Get embeddings\n",
    "encoder.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = encoder(X_tensor).cpu().numpy()  # Move back to CPU for numpy conversion\n",
    "\n",
    "# Plot embeddings\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=embeddings[:, 0], y=embeddings[:, 1], hue=domain_labels)\n",
    "plt.title('DANN Embeddings by Domain')\n",
    "plt.savefig('./src/models/dann/embeddings.png')\n",
    "plt.close()\n",
    "\n",
    "# 6. Save Model\n",
    "print(\"Saving models...\")\n",
    "# torch.save(encoder.state_dict(), './src/models/dann/dann_encoder.pth')\n",
    "# torch.save(domain_classifier.state_dict(), './src/models/dann/dann_domain_classifier.pth')\n",
    "# torch.save(cell_classifier.state_dict(), './src/models/dann/dann_cell_classifier.pth')\n",
    "\n",
    "print(\"Training complete!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch.venv",
   "language": "python",
   "name": "pytorch.venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
