## SLURM PROLOG ###############################################################
##    Job ID : 11224954
##  Job Name : dann_training
##  Nodelist : gpu2501
##      CPUs : 
##  Mem/Node : 196608 MB
## Directory : /oscar/scratch/edalal/universalgene
##   Job Started : Thu May  1 06:11:01 PM EDT 2025
###############################################################################
You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA RTX A5500') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name             | Type               | Params | Mode 
----------------------------------------------------------------
0 | encoder          | Encoder            | 2.1 M  | train
1 | domain_clf       | DomainClassifier   | 197 K  | train
2 | cell_clf         | CellClassifier     | 232 K  | train
3 | train_acc_cell   | MulticlassAccuracy | 0      | train
4 | train_acc_domain | MulticlassAccuracy | 0      | train
5 | val_acc_cell     | MulticlassAccuracy | 0      | train
6 | val_acc_domain   | MulticlassAccuracy | 0      | train
----------------------------------------------------------------
2.6 M     Trainable params
0         Non-trainable params
2.6 M     Total params
10.283    Total estimated model params size (MB)
17        Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
/oscar/scratch/edalal/universalgene/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
/oscar/scratch/edalal/universalgene/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
srun: Job step aborted: Waiting up to 182 seconds for job step to finish.
slurmstepd: error: *** STEP 11224954.0 ON gpu2501 CANCELLED AT 2025-05-01T18:28:17 ***
slurmstepd: error: *** JOB 11224954 ON gpu2501 CANCELLED AT 2025-05-01T18:28:17 ***
[rank: 0] Received SIGTERM: 15
Bypassing SIGTERM: 15
