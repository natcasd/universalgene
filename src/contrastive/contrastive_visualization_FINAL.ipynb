{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_contrastive import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/tabula_muris/preprocessed/tm_adata_test.pkl\"\n",
    "path_r = \"../data/tabula_muris/preprocessed_reduced/tm_adata_test.pkl\"\n",
    "\n",
    "X, domains, cells, adata = load_data(path)\n",
    "X_r, domains_r, cells_r, adata_r = load_data(path_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contrastive_model import ContrastiveModel\n",
    "\n",
    "CONTRASTIVE_TRANSFORMER_KEY=\"contrastive_transformer\"\n",
    "CONTRASTIVE_MLP_KEY=\"contrastive_mlp\"\n",
    "\n",
    "c_transformer_path = \"runs/contrastive_attention_d256_h2_l2_t1.0_05-08-23:08/final.ckpt\"\n",
    "c_mlp_path = \"runs/contrastive_dense_d512_l12_t1.0_05-08-21:16/final.ckpt\"\n",
    "\n",
    "\n",
    "c_transformer = ContrastiveModel.load_from_checkpoint(c_transformer_path)\n",
    "c_mlp = ContrastiveModel.load_from_checkpoint(c_mlp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContrastiveModel(\n",
       "  (encoder): DenseEncoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Linear(in_features=2000, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (5): LeakyReLU(negative_slope=0.01)\n",
       "      (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (7): Dropout(p=0.1, inplace=False)\n",
       "      (8): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "      (10): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (11): Dropout(p=0.1, inplace=False)\n",
       "      (12): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (13): LeakyReLU(negative_slope=0.01)\n",
       "      (14): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (15): Dropout(p=0.1, inplace=False)\n",
       "      (16): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (17): LeakyReLU(negative_slope=0.01)\n",
       "      (18): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (19): Dropout(p=0.1, inplace=False)\n",
       "      (20): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (21): LeakyReLU(negative_slope=0.01)\n",
       "      (22): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (23): Dropout(p=0.1, inplace=False)\n",
       "      (24): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (25): LeakyReLU(negative_slope=0.01)\n",
       "      (26): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (27): Dropout(p=0.1, inplace=False)\n",
       "      (28): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (29): LeakyReLU(negative_slope=0.01)\n",
       "      (30): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (31): Dropout(p=0.1, inplace=False)\n",
       "      (32): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (33): LeakyReLU(negative_slope=0.01)\n",
       "      (34): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (35): Dropout(p=0.1, inplace=False)\n",
       "      (36): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (37): LeakyReLU(negative_slope=0.01)\n",
       "      (38): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (39): Dropout(p=0.1, inplace=False)\n",
       "      (40): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (41): LeakyReLU(negative_slope=0.01)\n",
       "      (42): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (43): Dropout(p=0.1, inplace=False)\n",
       "      (44): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (45): LeakyReLU(negative_slope=0.01)\n",
       "      (46): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (47): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set tensors to the appropriate device\n",
    "x = torch.tensor(X, dtype=torch.float32).to(cuda_device)\n",
    "x_r = torch.tensor(X_r, dtype=torch.float32).to(cuda_device)\n",
    "\n",
    "c_transformer.to(cuda_device)\n",
    "c_mlp.to(cuda_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|████████████████████████████████████| 1931/1931 [00:09<00:00, 210.83it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 32  # Define a suitable batch size\n",
    "ct_embeddings_list = []\n",
    "cm_embeddings_list = []\n",
    "\n",
    "c_transformer.eval()\n",
    "c_mlp.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, x.size(0), batch_size), desc=\"Processing Batches\"):\n",
    "        x_batch = x[i:i + batch_size]\n",
    "        x_r_batch = x_r[i:i + batch_size]\n",
    "        \n",
    "        ct_embeddings_batch = c_transformer.encoder(x_r_batch)\n",
    "        cm_embeddings_batch = c_mlp.encoder(x_batch)\n",
    "        \n",
    "        ct_embeddings_list.append(ct_embeddings_batch)\n",
    "        cm_embeddings_list.append(cm_embeddings_batch)\n",
    "\n",
    "ct_embeddings = torch.cat(ct_embeddings_list, dim=0)\n",
    "cm_embeddings = torch.cat(cm_embeddings_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_998471/491995230.py:1: ImplicitModificationWarning: Setting element `.obsm['contrastive_transformer']` of view, initializing view as actual.\n",
      "  adata.obsm[CONTRASTIVE_TRANSFORMER_KEY] = ct_embeddings.cpu().numpy()\n"
     ]
    }
   ],
   "source": [
    "adata.obsm[CONTRASTIVE_TRANSFORMER_KEY] = ct_embeddings.cpu().numpy()\n",
    "adata.obsm[CONTRASTIVE_MLP_KEY] = cm_embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/anaconda-2023.09-0-7nso27ys7navjquejqdxqylhg7kuyvxo/lib/python3.11/site-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "sc.pp.neighbors(adata, use_rep=CONTRASTIVE_TRANSFORMER_KEY)  # Compute neighbors using latent space\n",
    "sc.tl.umap(adata)\n",
    "fig1 = sc.pl.umap(adata, color='tech', legend_loc=None, title='', frameon=False, size=50, return_fig=True, show=True)\n",
    "fig1.savefig('umap_transformer.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep=CONTRASTIVE_MLP_KEY)  # Compute neighbors using latent space\n",
    "sc.tl.umap(adata)\n",
    "fig = sc.pl.umap(adata, color='tech', legend_loc=None, title='', frameon=False, size=50, return_fig=True, show=True)\n",
    "fig.savefig('umap_mlp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/ndepiero/.local/lib/python3.11/site-packages/scanpy/preprocessing/_pca/__init__.py:438: FutureWarning: Argument `use_highly_variable` is deprecated, consider using the mask argument. Use_highly_variable=True can be called through mask_var=\"highly_variable\". Use_highly_variable=False can be called through mask_var=None\n",
      "  warn(msg, FutureWarning)\n",
      "Computing neighbors: 100%|██████████████████████████████████████████| 2/2 [01:46<00:00, 53.20s/it]\n",
      "Embeddings:   0%|\u001b[32m                                                           \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0mWARNING:jax._src.xla_bridge:An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "from scib_metrics.benchmark import Benchmarker\n",
    "bm = Benchmarker(\n",
    "    adata,\n",
    "    batch_key='tech',\n",
    "    label_key='cell_ontology_class',\n",
    "    embedding_obsm_keys=[CONTRASTIVE_TRANSFORMER_KEY, CONTRASTIVE_MLP_KEY],\n",
    "    n_jobs=-1\n",
    ")\n",
    "bm.benchmark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python env for universalgene project",
   "language": "python",
   "name": "universalgene"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
